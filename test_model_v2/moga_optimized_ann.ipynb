{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Machine Learning and Deep Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Genetic Algorithm Libraries\n",
    "from deap import base, creator, tools, algorithms\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T18:13:48.327404800Z",
     "start_time": "2024-12-17T18:13:43.827790600Z"
    }
   },
   "id": "f4c60248f39555b4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Fix random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T18:13:49.719005100Z",
     "start_time": "2024-12-17T18:13:49.687099600Z"
    }
   },
   "id": "5582a823dd9a9584"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class StrokeModelOptimizer:\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"\n",
    "        Initialize data, Genetic Algorithm (GA) settings, and constraints.\n",
    "        \"\"\"\n",
    "        # Load and preprocess data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.scaler = self.load_and_preprocess_data(filepath)\n",
    "\n",
    "        # Enhanced GA Configuration\n",
    "        self.POPULATION_SIZE = 10  # Increased population size\n",
    "        self.MAX_GENERATIONS = 5  # More generations\n",
    "        self.CROSSOVER_PROB = 0.8  # Increased crossover probability\n",
    "        self.MUTATION_PROB = 0.3  # Increased mutation probability\n",
    "\n",
    "        # Gene configuration: ranges for hyperparameters with wider exploration\n",
    "        self.GENE_CONFIGS = {\n",
    "            'neurons_layer1': (16, 256),  # Wider range\n",
    "            'neurons_layer2': (8, 128),  # Wider range\n",
    "            'dropout_rate1': (0.1, 0.6),  # Expanded dropout range\n",
    "            'dropout_rate2': (0.1, 0.4),  # Expanded dropout range\n",
    "            'learning_rate': (0.0001, 0.01),  # Wider learning rate range\n",
    "            'l2_reg': (1e-4, 1e-1)  # Expanded regularization range\n",
    "        }\n",
    "        self.TRAINING_EPOCHS = 5\n",
    "        # Tracking variables\n",
    "        self.generation_best_loss = []\n",
    "        self.generation_diversity = []\n",
    "        self.generation_individuals = []\n",
    "        self.generation_best_accuracy = []\n",
    "        self.best_individual = None\n",
    "\n",
    "        self.setup_deap_framework()\n",
    "\n",
    "    def load_and_preprocess_data(self, filepath):\n",
    "        \"\"\"Load dataset and preprocess.\"\"\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        X = df.drop('stroke', axis=1)\n",
    "        y = df['stroke']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "    def calculate_population_diversity(self, population):\n",
    "        \"\"\"Calculate population diversity based on gene variations\"\"\"\n",
    "        if not population:\n",
    "            return 0\n",
    "\n",
    "        gene_diversity = []\n",
    "        for gene_index in range(len(population[0])):\n",
    "            gene_values = [ind[gene_index] for ind in population]\n",
    "            gene_diversity.append(np.std(gene_values))\n",
    "        return np.mean(gene_diversity)\n",
    "\n",
    "    def setup_deap_framework(self):\n",
    "        \"\"\"Setup DEAP for GA optimization with enhanced diversity.\"\"\"  # Fix to mitigate premature convergence\n",
    "        creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, 1.0))  # Minimize loss, maximize accuracy\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "        self.toolbox = base.Toolbox()\n",
    "\n",
    "        # Gene initialization with more dynamic ranges\n",
    "        for gene, (low, high) in self.GENE_CONFIGS.items():\n",
    "            self.toolbox.register(f\"attr_{gene}\", random.uniform, low, high)\n",
    "\n",
    "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                              (self.toolbox.attr_neurons_layer1,\n",
    "                               self.toolbox.attr_neurons_layer2,\n",
    "                               self.toolbox.attr_dropout_rate1,\n",
    "                               self.toolbox.attr_dropout_rate2,\n",
    "                               self.toolbox.attr_learning_rate,\n",
    "                               self.toolbox.attr_l2_reg), n=1)\n",
    "\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "\n",
    "        # Enhanced crossover and mutation\n",
    "        self.toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "        self.toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.3)\n",
    "\n",
    "        # Custom selection with tournament selection to maintain diversity\n",
    "        def diversity_tournament_selection(individuals, k, tournsize=3):\n",
    "            \"\"\"Tournament selection with diversity consideration\"\"\"\n",
    "            selected = []\n",
    "            for _ in range(k):\n",
    "                # Perform tournament selection\n",
    "                tournament = random.sample(individuals, tournsize)\n",
    "                winner = min(tournament, key=lambda ind: ind.fitness.values[0])\n",
    "                selected.append(winner)\n",
    "            return selected\n",
    "\n",
    "        self.toolbox.register(\"select\", diversity_tournament_selection)\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate_individual)\n",
    "\n",
    "    def build_ann(self, individual):\n",
    "        \"\"\"Build an ANN model based on individual hyperparameters.\"\"\"\n",
    "        neurons1, neurons2, drop1, drop2, lr, l2_reg = individual\n",
    "        model = Sequential([\n",
    "            Dense(int(neurons1), activation='relu', input_shape=(self.X_train.shape[1],),\n",
    "                  kernel_regularizer=l2(l2_reg)),\n",
    "            Dropout(drop1),\n",
    "            Dense(int(neurons2), activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "            Dropout(drop2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # def evaluate_individual(self, individual):\n",
    "    #     \"\"\"Evaluate the performance of an ANN defined by individual genes.\"\"\"\n",
    "    #     try:\n",
    "    #         model = self.build_ann(individual)\n",
    "    #         early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    #         model.fit(self.X_train, self.y_train,\n",
    "    #                             epochs=self.TRAINING_EPOCHS,\n",
    "    #                             batch_size=64,\n",
    "    #                             validation_split=0.2,\n",
    "    #                             verbose=0,\n",
    "    #                             callbacks=[early_stopping])\n",
    "    # \n",
    "    #         y_pred = (model.predict(self.X_test) > 0.5).astype(int)\n",
    "    #         acc = accuracy_score(self.y_test, y_pred)\n",
    "    #         loss = model.evaluate(self.X_test, self.y_test, verbose=0)[0]\n",
    "    # \n",
    "    #         return loss, -acc\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Evaluation error: {e}\")\n",
    "    #         return 1e6, 0\n",
    "    \n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"Evaluate the performance of an ANN defined by individual genes.\"\"\"\n",
    "        try:\n",
    "            # Build model using individual's genes\n",
    "            model = self.build_ann(individual)\n",
    "        \n",
    "            # Early stopping to prevent overfitting\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "            # Train the model\n",
    "            model.fit(self.X_train, self.y_train,\n",
    "                            epochs=self.TRAINING_EPOCHS,\n",
    "                            batch_size=64,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=0,\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "        # Evaluate on test data\n",
    "            loss, acc = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "\n",
    "        # Fitness: Minimize loss and maximize accuracy\n",
    "            return loss, -acc  # Note: Accuracy is negated for maximization\n",
    "        except Exception as e:\n",
    "            print(f\"Evaluation error: {e}\")\n",
    "            return 1e6, 0  # Penalize invalid individuals\n",
    "\n",
    "\n",
    "    def run_optimization(self):\n",
    "        # Reset tracking variables\n",
    "        self.generation_best_loss = []\n",
    "        self.generation_diversity = []\n",
    "        self.generation_individuals = []\n",
    "        self.generation_best_accuracy = []\n",
    "\n",
    "        # Create initial population\n",
    "        pop = self.toolbox.population(n=self.POPULATION_SIZE)\n",
    "\n",
    "        # Evaluate initial population\n",
    "        fitnesses = list(map(self.toolbox.evaluate, pop))\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Generational loop with enhanced tracking and diversity preservation\n",
    "        for gen in range(self.MAX_GENERATIONS):\n",
    "            # Calculate and track population diversity\n",
    "            current_diversity = self.calculate_population_diversity(pop)\n",
    "            self.generation_diversity.append(current_diversity)\n",
    "\n",
    "            # Select next generation individuals\n",
    "            offspring = self.toolbox.select(pop, len(pop))\n",
    "            offspring = list(map(self.toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover and mutation\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CROSSOVER_PROB:\n",
    "                    self.toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTATION_PROB:\n",
    "                    self.toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate individuals with invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = map(self.toolbox.evaluate, invalid_ind)\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "\n",
    "            # Replace population\n",
    "            pop[:] = offspring\n",
    "\n",
    "            # Track generation best fitness\n",
    "            best_ind = tools.selBest(pop, 1)[0]\n",
    "            self.generation_best_loss.append(best_ind.fitness.values[0])\n",
    "            self.generation_best_accuracy.append(-best_ind.fitness.values[1])  # Best accuracy\n",
    "\n",
    "            # Track information about each individual in this generation\n",
    "            self.generation_individuals.append([])  # Create an empty list for this generation\n",
    "            for ind in offspring:\n",
    "                ind_info = {\"individual\": ind, \"fitness\": ind.fitness.values}\n",
    "                self.generation_individuals[-1].append(ind_info)  # Add info to current generation list\n",
    "\n",
    "            # Print generation details\n",
    "            print(f\"Generation {gen + 1}:\")\n",
    "            print(f\"Diversity: {current_diversity}\")\n",
    "            print(\"\\nAll Individuals in this Generation:\")\n",
    "            for i, ind_info in enumerate(self.generation_individuals[-1], 1):\n",
    "                print(f\"Individual {i}: {ind_info['individual']}\")\n",
    "                print(f\"Fitness: {ind_info['fitness']}\\n\")\n",
    "\n",
    "            print(\"Best Individual Hyperparameters:\", best_ind)\n",
    "            print(\"\")\n",
    "            print(f\"Best Loss: {best_ind.fitness.values[0]}\")\n",
    "            print(f\"Best Accuracy: {-best_ind.fitness.values[1]}\")\n",
    "            print(\"\")\n",
    "            print(\"Best Fitness (Loss, Accuracy):\", best_ind.fitness.values)\n",
    "\n",
    "        # Store the best overall individual\n",
    "        self.best_individual = tools.selBest(pop, 1)[0]\n",
    "\n",
    "        # Visualize results\n",
    "        self.visualize_results(pop)\n",
    "\n",
    "    def visualize_results(self, pop):\n",
    "        # Create a figure with multiple subplots\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "        # 1. Convergence Plot\n",
    "        axs[0, 0].plot(range(1, len(self.generation_best_loss) + 1),\n",
    "                       self.generation_best_loss, marker='o', label=\"Best Loss\")\n",
    "        axs[0, 0].set_title('Convergence Plot (Loss)')\n",
    "        axs[0, 0].set_xlabel('Generation')\n",
    "        axs[0, 0].set_ylabel('Loss')\n",
    "        \n",
    "        # 2. Convergence Plot (Accuracy)\n",
    "        axs[0, 1].plot(range(1, len(self.generation_best_accuracy) + 1), \n",
    "                   self.generation_best_accuracy, marker='o', color='orange', label=\"Best Accuracy\")\n",
    "        axs[0, 1].set_title('Convergence Plot (Accuracy)')\n",
    "        axs[0, 1].set_xlabel('Generation')\n",
    "        axs[0, 1].set_ylabel('Accuracy')\n",
    "        axs[0, 1].legend()\n",
    "\n",
    "        # # 2. Population Diversity Plot\n",
    "        # axs[0, 1].plot(range(1, len(self.generation_diversity) + 1),\n",
    "        #                self.generation_diversity, marker='o', color='green')\n",
    "        # axs[0, 1].set_title('Population Diversity Over Generations')\n",
    "        # axs[0, 1].set_xlabel('Generation')\n",
    "        # axs[0, 1].set_ylabel('Diversity Metric')\n",
    "\n",
    "        # 3. Pareto Front Visualization\n",
    "        losses = [ind.fitness.values[0] for ind in pop]\n",
    "        accuracies = [-ind.fitness.values[1] for ind in pop]\n",
    "        axs[1, 0].scatter(losses, accuracies, c='b', label=\"Pareto Front\")\n",
    "        axs[1, 0].set_xlabel(\"Loss\")\n",
    "        axs[1, 0].set_ylabel(\"Accuracy\")\n",
    "        axs[1, 0].set_title(\"Pareto Front Visualization\")\n",
    "        axs[1, 0].legend()\n",
    "\n",
    "        # 4. Hyperparameter Distribution\n",
    "        hyperparameter_names = ['Neurons Layer 1', 'Neurons Layer 2',\n",
    "                                'Dropout Rate 1', 'Dropout Rate 2',\n",
    "                                'Learning Rate', 'L2 Regularization']\n",
    "        hyperparameter_values = list(zip(*pop))\n",
    "\n",
    "        for i in range(len(hyperparameter_names)):\n",
    "            axs[1, 1].hist(hyperparameter_values[i], bins=10,\n",
    "                           alpha=0.5, label=hyperparameter_names[i])\n",
    "        axs[1, 1].set_title('Hyperparameter Distribution')\n",
    "        axs[1, 1].set_xlabel('Value')\n",
    "        axs[1, 1].set_ylabel('Frequency')\n",
    "        axs[1, 1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Use the best individual's hyperparameters to build and train the final model\n",
    "        print(\"\\nBest Overall Individual Hyperparameters:\", self.best_individual)\n",
    "\n",
    "        # Build final model using BEST optimized hyperparameters\n",
    "        final_model = self.build_ann(self.best_individual)\n",
    "\n",
    "        # Train with full training data using optimized hyperparameters\n",
    "        neurons1, neurons2, drop1, drop2, lr, l2_reg = self.best_individual\n",
    "        print(\"\\nTraining Final Model with Optimized Hyperparameters:\")\n",
    "        print(f\"Layer 1 Neurons: {int(neurons1)}\")\n",
    "        print(f\"Layer 2 Neurons: {int(neurons2)}\")\n",
    "        print(f\"Dropout Rate 1: {drop1}\")\n",
    "        print(f\"Dropout Rate 2: {drop2}\")\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        print(f\"L2 Regularization: {l2_reg}\")\n",
    "\n",
    "        # Train the model\n",
    "        final_model.fit(self.X_train, self.y_train,\n",
    "                        epochs=self.TRAINING_EPOCHS,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1)\n",
    "\n",
    "        # Predictions and Evaluation\n",
    "        y_pred = (final_model.predict(self.X_test) > 0.5).astype(int)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "        # Additional Visualizations\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Confusion Matrix\n",
    "        plt.subplot(1, 3, 1)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "\n",
    "        # ROC Curve\n",
    "        plt.subplot(1, 3, 2)\n",
    "        fpr, tpr, _ = roc_curve(self.y_test, final_model.predict(self.X_test))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc(fpr, tpr):.2f}')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Precision-Recall Curve\n",
    "        plt.subplot(1, 3, 3)\n",
    "        precision, recall, _ = precision_recall_curve(self.y_test, final_model.predict(self.X_test))\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Precision-Recall Curve\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T18:13:51.731536800Z",
     "start_time": "2024-12-17T18:13:51.677350400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the optimizer\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = r\"C:\\Users\\HP\\Documents\\GitHub\\ci-coursework\\cleaned-stroke-prediction-dataset-balanced.csv\"\n",
    "    optimizer = StrokeModelOptimizer(filepath)\n",
    "    optimizer.run_optimization()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3994b81ad7f61034"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abb3942deb19b6d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
