{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:31:56.402952200Z",
     "start_time": "2024-12-16T17:31:56.387310600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# Machine Learning and Deep Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "# Genetic Algorithm Libraries\n",
    "import deap\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:31:56.962400200Z",
     "start_time": "2024-12-16T17:31:56.893524500Z"
    }
   },
   "id": "26ca0a3681a4fc92"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "class EpochTimeCallback(Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to track epoch training times\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        print(f\"Epoch {epoch + 1} took {epoch_time:.4f} seconds\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:31:57.805897500Z",
     "start_time": "2024-12-16T17:31:57.795726200Z"
    }
   },
   "id": "bb853ffc63a9bf8c"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class StrokeModelOptimizer:\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"\n",
    "        Initialize the optimizer with data and genetic algorithm parameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filepath : str\n",
    "            Path to the stroke prediction dataset\n",
    "        \"\"\"\n",
    "        # Data Loading and Preprocessing\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, self.scaler = self.load_and_preprocess_data(filepath)\n",
    "        \n",
    "        # GA Configuration\n",
    "        self.POPULATION_SIZE = 50\n",
    "        self.MAX_GENERATIONS = 20\n",
    "        self.CROSSOVER_PROB = 0.7\n",
    "        self.MUTATION_PROB = 0.2\n",
    "        \n",
    "        # Chromosome Gene Ranges with Explicit Constraints\n",
    "        self.GENE_CONFIGS = {\n",
    "            'neurons_layer1': (16, 128),   # First layer neurons\n",
    "            'neurons_layer2': (8, 64),     # Second layer neurons\n",
    "            'dropout_rate1': (0.1, 0.5),   # First dropout rate\n",
    "            'dropout_rate2': (0.1, 0.3),   # Second dropout rate\n",
    "            'learning_rate': (1e-4, 1e-2), # Learning rate\n",
    "            'l2_reg': (1e-4, 1e-2)         # L2 regularization strength\n",
    "        }\n",
    "        \n",
    "        # Optimization Constraints\n",
    "        self.CONSTRAINTS = {\n",
    "            'min_accuracy': 0.75,\n",
    "            'max_false_negative_rate': 0.2,\n",
    "            'min_recall': 0.7,\n",
    "            'max_training_time': 300,  # 5 minutes\n",
    "            'max_total_params': 10000\n",
    "        }\n",
    "        \n",
    "        # Setup DEAP framework\n",
    "        self.setup_deap_framework()\n",
    "        \n",
    "    def load_and_preprocess_data(self, filepath):\n",
    "        \"\"\"\n",
    "        Load and preprocess stroke prediction dataset\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        X = df.drop('stroke', axis=1)\n",
    "        y = df['stroke']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "    \n",
    "    def setup_deap_framework(self):\n",
    "        \"\"\"\n",
    "        Setup DEAP's multi-objective optimization framework\n",
    "        \"\"\"\n",
    "        # Multi-objective maximization problem\n",
    "        creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0, -1.0, 1.0))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "        \n",
    "        # Toolbox setup\n",
    "        self.toolbox = base.Toolbox()\n",
    "        \n",
    "        # Gene generation functions\n",
    "        for gene, (low, high) in self.GENE_CONFIGS.items():\n",
    "            self.toolbox.register(f\"attr_{gene}\", random.uniform, low, high)\n",
    "        \n",
    "        # Individual and population creation\n",
    "        self.toolbox.register(\"individual\", \n",
    "                               tools.initCycle, \n",
    "                               creator.Individual,\n",
    "                               (self.toolbox.attr_neurons_layer1, \n",
    "                                self.toolbox.attr_neurons_layer2,\n",
    "                                self.toolbox.attr_dropout_rate1,\n",
    "                                self.toolbox.attr_dropout_rate2,\n",
    "                                self.toolbox.attr_learning_rate,\n",
    "                                self.toolbox.attr_l2_reg), \n",
    "                               n=1)\n",
    "        \n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        \n",
    "        # Genetic Operators\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate_individual)\n",
    "        self.toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "        self.toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "        self.toolbox.register(\"select\", tools.selNSGA2)\n",
    "        \n",
    "    def create_ann_model(self, individual):\n",
    "        \"\"\"\n",
    "        Create ANN model with explicit constraints\n",
    "        \"\"\"\n",
    "        neurons_layer1, neurons_layer2, dropout1, dropout2, learning_rate, l2_reg = individual\n",
    "\n",
    "        # Constraint Checks\n",
    "        neurons_layer1 = max(16, min(128, int(neurons_layer1)))\n",
    "        neurons_layer2 = max(8, min(64, int(neurons_layer2)))\n",
    "        dropout1 = max(0.1, min(0.5, dropout1))\n",
    "        dropout2 = max(0.1, min(0.3, dropout2))\n",
    "        learning_rate = max(1e-4, min(1e-2, learning_rate))\n",
    "        l2_reg = max(1e-4, min(1e-2, l2_reg))\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(neurons_layer1, activation='relu', \n",
    "                  input_shape=(self.X_train.shape[1],), \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "            Dropout(dropout1),\n",
    "            Dense(neurons_layer2, activation='relu', \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "            Dropout(dropout2),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        # Check total model parameters\n",
    "        total_params = sum([layer.count_params() for layer in model.layers])\n",
    "        if total_params > self.CONSTRAINTS['max_total_params']:\n",
    "            raise ValueError(\"Model exceeds maximum parameter constraint\")\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def train_model_with_tqdm(self, model, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train model with TQDM progress tracking\n",
    "        \"\"\"\n",
    "        epochs = 2\n",
    "        progress_bar = tqdm(range(epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "        \n",
    "        # Epoch time tracking callback\n",
    "        epoch_time_callback = EpochTimeCallback()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            callbacks=[\n",
    "                early_stopping,\n",
    "                epoch_time_callback,\n",
    "                tf.keras.callbacks.LambdaCallback(\n",
    "                    on_epoch_end=lambda epoch, logs: progress_bar.set_postfix(\n",
    "                        loss=f\"{logs.get('loss'):.4f}\",\n",
    "                        val_loss=f\"{logs.get('val_loss'):.4f}\"\n",
    "                    )\n",
    "                )\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        progress_bar.close()\n",
    "        print(f\"Epoch {epochs + 1} completed.\")\n",
    "\n",
    "        return history, epoch_time_callback\n",
    "    \n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"\n",
    "        Enhanced evaluation with performance constraints\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create and train model\n",
    "            model = self.create_ann_model(individual)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            history, epoch_time_callback = self.train_model_with_tqdm(\n",
    "                model, self.X_train, self.y_train\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Performance Metrics with Constraint Checks\n",
    "            y_pred_proba = model.predict(self.X_test)\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "            \n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            recall = recall_score(self.y_test, y_pred)\n",
    "            false_negative_rate = np.sum((y_pred == 0) & (self.y_test == 1)) / np.sum(self.y_test == 1)\n",
    "            \n",
    "            # Constraint Validation\n",
    "            if (accuracy < self.CONSTRAINTS['min_accuracy'] or \n",
    "                recall < self.CONSTRAINTS['min_recall'] or \n",
    "                false_negative_rate > self.CONSTRAINTS['max_false_negative_rate'] or \n",
    "                training_time > self.CONSTRAINTS['max_training_time']):\n",
    "                print(f\"Evaluation failed due to constraints: {accuracy}, {recall}, {false_negative_rate}, {training_time}\")\n",
    "                return 1.0, float('inf'), float('inf'), 0.0\n",
    "            \n",
    "            return (\n",
    "                false_negative_rate,    # Minimize\n",
    "                training_time,           # Minimize\n",
    "                model.count_params(),    # Minimize\n",
    "                accuracy                 # Maximize\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Evaluation Error: {e}\")\n",
    "            return 1.0, float('inf'), float('inf'), 0.0\n",
    "        \n",
    "    def run_optimization(self):\n",
    "        \"\"\"\n",
    "        Run multi-objective genetic algorithm optimization\n",
    "        \"\"\"\n",
    "        # Initialize population\n",
    "        population = self.toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        # Hall of Fame to track best solutions\n",
    "        hall_of_fame = tools.ParetoFront()\n",
    "        \n",
    "        # Create statistics tracker\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean, axis=0)\n",
    "        stats.register(\"min\", np.min, axis=0)\n",
    "        \n",
    "        # Run NSGA-II algorithm\n",
    "        population, logbook = algorithms.eaMuPlusLambda(\n",
    "            population, \n",
    "            self.toolbox, \n",
    "            mu=self.POPULATION_SIZE, \n",
    "            lambda_=self.POPULATION_SIZE, \n",
    "            cxpb=self.CROSSOVER_PROB, \n",
    "            mutpb=self.MUTATION_PROB, \n",
    "            stats=stats,\n",
    "            halloffame=hall_of_fame, \n",
    "            ngen=self.MAX_GENERATIONS,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return hall_of_fame, population, logbook\n",
    "    \n",
    "    def visualize_optimization_results(self, hall_of_fame, logbook):\n",
    "        \"\"\"\n",
    "        Visualization of genetic algorithm optimization process\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Pareto Front Visualization\n",
    "        plt.subplot(2, 2, 1)\n",
    "        pareto_front = np.array([ind.fitness.values for ind in hall_of_fame])\n",
    "        plt.scatter(pareto_front[:, 0], pareto_front[:, 1], \n",
    "                    c=pareto_front[:, 3], cmap='viridis')\n",
    "        plt.title('Pareto Front: False Negative Rate vs Training Time')\n",
    "        plt.xlabel('False Negative Rate')\n",
    "        plt.ylabel('Training Time')\n",
    "        plt.colorbar(label='Accuracy')\n",
    "        \n",
    "        # 2. Convergence Plot\n",
    "        plt.subplot(2, 2, 2)\n",
    "        gen_stats = logbook.select(\"gen\")\n",
    "        avg_fitness = logbook.select(\"avg\")\n",
    "        plt.plot(gen_stats, [x[0] for x in avg_fitness], label='Avg False Negative Rate')\n",
    "        plt.plot(gen_stats, [x[1] for x in avg_fitness], label='Avg Training Time')\n",
    "        plt.title('Optimization Convergence')\n",
    "        plt.xlabel('Generations')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 3. Best Individual Performance Tracking\n",
    "        plt.subplot(2, 2, 3)\n",
    "        best_individuals = [ind for ind in hall_of_fame]\n",
    "        metrics = np.array([ind.fitness.values for ind in best_individuals])\n",
    "        metrics_names = ['False Negative Rate', 'Training Time', 'Model Complexity', 'Accuracy']\n",
    "        \n",
    "        for i in range(4):\n",
    "            plt.plot(metrics[:, i], label=metrics_names[i])\n",
    "        plt.title('Best Individual Metrics Progression')\n",
    "        plt.xlabel('Pareto Solutions')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 4. Distribution of Hyperparameters\n",
    "        plt.subplot(2, 2, 4)\n",
    "        hyperparams = np.array([list(ind)[:4] for ind in hall_of_fame])\n",
    "        param_names = list(self.GENE_CONFIGS.keys())[:4]\n",
    "        for i in range(4):\n",
    "            plt.hist(hyperparams[:, i], bins=20, alpha=0.5, label=param_names[i])\n",
    "        plt.title('Hyperparameter Distribution')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def visualize_epoch_training_times(self, epoch_times):\n",
    "        \"\"\"\n",
    "        Visualize epoch training times\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(epoch_times) + 1), epoch_times, marker='o')\n",
    "        plt.title('Epoch Training Times')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Training Time (seconds)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_best_model_performance(self, best_model, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Comprehensive model performance visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_proba = best_model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        # 1. Confusion Matrix\n",
    "        plt.subplot(2, 2, 1)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        \n",
    "        # 2. Classification Report\n",
    "        plt.subplot(2, 2, 2)\n",
    "        class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(class_report).transpose()\n",
    "        sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap='YlGnBu')\n",
    "        plt.title('Classification Metrics')\n",
    "        \n",
    "        # 3. ROC Curve\n",
    "        plt.subplot(2, 3, 3)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        # 4. Precision-Recall Curve\n",
    "        plt.subplot(2, 3, 4)\n",
    "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve (AP = {avg_precision:.2f})')\n",
    "        \n",
    "        # 5. Distribution of Predictions\n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.hist([y_pred_proba[y_test == 0], y_pred_proba[y_test == 1]], \n",
    "                 label=['Negative', 'Positive'], \n",
    "                 color=['blue', 'red'], \n",
    "                 alpha=0.6, \n",
    "                 bins=30)\n",
    "        plt.title('Distribution of Prediction Probabilities')\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        # 6. Prediction Error Analysis\n",
    "        plt.subplot(2, 3, 6)\n",
    "        prediction_errors = np.abs(y_test - y_pred_proba.ravel())\n",
    "        plt.hist(prediction_errors, bins=30, color='green', alpha=0.7)\n",
    "        plt.title('Prediction Error Distribution')\n",
    "        plt.xlabel('Absolute Prediction Error')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:31:58.856776400Z",
     "start_time": "2024-12-16T17:31:58.759775Z"
    }
   },
   "id": "ea95c2cc25857b72"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the stroke prediction model optimization\n",
    "    \"\"\"\n",
    "    # Replace with your actual dataset path\n",
    "    filepath = r'C:\\Users\\HP\\Documents\\GitHub\\ci-coursework\\cleaned-stroke-prediction-dataset-balanced.csv'\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimizer = StrokeModelOptimizer(filepath)\n",
    "    \n",
    "    # Run multi-objective optimization\n",
    "    hall_of_fame, population, logbook = optimizer.run_optimization()\n",
    "    \n",
    "    # Visualize optimization results\n",
    "    optimizer.visualize_optimization_results(hall_of_fame, logbook)\n",
    "    \n",
    "    # Select the best individual (first in the Pareto front)\n",
    "    best_individual = hall_of_fame[0]\n",
    "    \n",
    "    # Create and train the best model\n",
    "    best_model = optimizer.create_ann_model(best_individual)\n",
    "    \n",
    "    # Train the model with tqdm and get epoch times\n",
    "    history, epoch_time_callback = optimizer.train_model_with_tqdm(\n",
    "        best_model, optimizer.X_train, optimizer.y_train\n",
    "    )\n",
    "    \n",
    "    # Visualize epoch training times\n",
    "    optimizer.visualize_epoch_training_times(epoch_time_callback.epoch_times)\n",
    "    \n",
    "    # Visualize best model performance\n",
    "    optimizer.visualize_best_model_performance(best_model, optimizer.X_test, optimizer.y_test)\n",
    "    \n",
    "    # Optional: Save best model\n",
    "    best_model.save('best_stroke_prediction_model.h5')\n",
    "    print(\"Best model saved successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:31:59.888635500Z",
     "start_time": "2024-12-16T17:31:59.857107400Z"
    }
   },
   "id": "1a6a70e2a64d75a1"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:02<?, ?epoch/s, loss=0.4113, val_loss=0.3258]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 2.2443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:02<?, ?epoch/s, loss=0.3313, val_loss=0.3152]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4491 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m38/59\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4912, val_loss=0.3686]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3098 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3374, val_loss=0.3192]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4488 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.6435, val_loss=0.4287]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.2701 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4158, val_loss=0.3512]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4372 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4209, val_loss=0.3135]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.2738 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3206, val_loss=0.2912]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4524 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m53/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4143, val_loss=0.3262]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3317 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3247, val_loss=0.3121]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4383 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m55/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4990, val_loss=0.3356]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3212 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3228, val_loss=0.3052]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4345 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m49/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3503, val_loss=0.2846]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3102 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.2851, val_loss=0.2812]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4623 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m48/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.5584, val_loss=0.4115]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3134 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3878, val_loss=0.3618]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4403 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m44/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.6068, val_loss=0.3690]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.4699 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3408, val_loss=0.3207]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4497 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m57/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.5695, val_loss=0.4089]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.4088 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3674, val_loss=0.3357]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4440 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4567, val_loss=0.3359]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.4198 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3528, val_loss=0.3331]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4895 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m49/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.6199, val_loss=0.4267]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.3991 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3854, val_loss=0.3477]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4234 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m44/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4208, val_loss=0.3388]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.4582 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3343, val_loss=0.3145]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4582 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m55/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m59/59\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Error: cannot reshape array of size 3534400 into shape (1880,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:00<?, ?epoch/s]\u001B[A\u001B[A\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.4922, val_loss=0.3345]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 1.4442 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Progress:   0%|          | 0/2 [00:01<?, ?epoch/s, loss=0.3345, val_loss=0.3159]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 took 0.4332 seconds\n",
      "Epoch 3 completed.\n",
      "\u001B[1m 1/59\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m2s\u001B[0m 47ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:   0%|          | 0/50 [36:25<?, ?epoch/s, loss=0.2798, val_loss=0.2722]\n",
      "Training Progress:   0%|          | 0/5 [32:28<?, ?epoch/s, loss=0.3118, val_loss=0.3110]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[75], line 12\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m StrokeModelOptimizer(filepath)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Run multi-objective optimization\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m hall_of_fame, population, logbook \u001B[38;5;241m=\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_optimization\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Visualize optimization results\u001B[39;00m\n\u001B[0;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mvisualize_optimization_results(hall_of_fame, logbook)\n",
      "Cell \u001B[1;32mIn[74], line 232\u001B[0m, in \u001B[0;36mStrokeModelOptimizer.run_optimization\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    229\u001B[0m stats\u001B[38;5;241m.\u001B[39mregister(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, np\u001B[38;5;241m.\u001B[39mmin, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# Run NSGA-II algorithm\u001B[39;00m\n\u001B[1;32m--> 232\u001B[0m population, logbook \u001B[38;5;241m=\u001B[39m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meaMuPlusLambda\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpopulation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoolbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPOPULATION_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPOPULATION_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcxpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCROSSOVER_PROB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmutpb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMUTATION_PROB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhalloffame\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhall_of_fame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mngen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMAX_GENERATIONS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m    243\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hall_of_fame, population, logbook\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\deap\\algorithms.py:302\u001B[0m, in \u001B[0;36meaMuPlusLambda\u001B[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001B[0m\n\u001B[0;32m    300\u001B[0m invalid_ind \u001B[38;5;241m=\u001B[39m [ind \u001B[38;5;28;01mfor\u001B[39;00m ind \u001B[38;5;129;01min\u001B[39;00m population \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalid]\n\u001B[0;32m    301\u001B[0m fitnesses \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mmap(toolbox\u001B[38;5;241m.\u001B[39mevaluate, invalid_ind)\n\u001B[1;32m--> 302\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ind, fit \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(invalid_ind, fitnesses):\n\u001B[0;32m    303\u001B[0m     ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m fit\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m halloffame \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[1;32mIn[74], line 190\u001B[0m, in \u001B[0;36mStrokeModelOptimizer.evaluate_individual\u001B[1;34m(self, individual)\u001B[0m\n\u001B[0;32m    187\u001B[0m training_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# Performance Metrics with Constraint Checks\u001B[39;00m\n\u001B[1;32m--> 190\u001B[0m y_pred_proba \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    191\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m (y_pred_proba \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m    193\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_test, y_pred)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:558\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[0;32m    557\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m--> 558\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    559\u001B[0m     batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_function(data)\n\u001B[0;32m    560\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m append_to_outputs(batch_outputs, outputs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:538\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict.<locals>.get_data\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_execution):\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 538\u001B[0m         single_step_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mStopIteration\u001B[39;00m, tf\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mOutOfRangeError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__len__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    541\u001B[0m             \u001B[38;5;66;03m# Suppress the error when still have remaining data.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    825\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 826\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    827\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[0;32m    774\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[1;32m--> 776\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    777\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    778\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3108\u001B[0m, in \u001B[0;36miterator_get_next\u001B[1;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[0;32m   3106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3107\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3108\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3109\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mIteratorGetNext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3110\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3112\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:32:33.106626700Z",
     "start_time": "2024-12-16T17:32:00.928170800Z"
    }
   },
   "id": "d367dacc2bd988f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d3399d7589596ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
